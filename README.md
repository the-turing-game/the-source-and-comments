# The source and comments

## The preamble
Let me quote: 
> If the meaning of the words "machine" and "think" are to be found by
examining how they are commonly used it is difficult to escape the conclusion that the
meaning and the answer to the question, "Can machines think?" is to be sought in a
statistical survey such as a Gallup poll. But this is absurd.

Mr. Turing is trying to tell us that deciding this question by a simple majority
voting is not a viable method ('absurd' - wildly unreasonable, illogical, or 
inappropriate), but somehow it sounds as a rejection of any measurable response 
of the Society to the experiments with automated deception that he is about to 
contemplate in the rest of the article...<br>
However! If you think about the procedure of training Large Language Models it is
almost exactly what he is describing as a "...statistical survey such as Gallup poll."

## The Turing Game
It is hard to believe that this text had been written by a person with training
in mathematics... First of all, it is more or less clear that the players A and B 
who are rigidly classified as 'man' (A) and 'woman' (B) are in the beginning of the 
game assigned symbolic names X and Y, but, instead of clearly saying it in the 
very beginning we are left with the only option to guess it from the format of 
the question given in quotes.

It gradually occurs to a meticulous enough reader, that not only the game is 
asymmetric in terms of classes/sex (only a man (A) is supposed to deceive the 
interrogator (C) the woman (B) is _not_ supposed to deceive); more than that, she
is supposed to help the interrogator in discovering the deception! 
This asymmetry of goals as we will see changes the game from what is 
routinely called 'the Turing test' to a partly cooperative game with incomplete 
information, which is significantly more complex.

The third circumstance that comes out of the description is that players A and B
are _in the same room_ which means that they have complete information about
the answers and statements of each other! ...and, of course, that was the 'fun'
part (for other people present in the room) of the 'salon game' - the prototype 
of this 'Turing Game'. 

And then - this: 
> We now ask the question, "What will happen when a machine takes the part of A in this
game?" Will the interrogator decide wrongly as often when the game is played like this as
he does when the game is played between a man and a woman? These questions replace
our original, "Can machines think?"

So... a Machine will take a place of a _man_ (A) and pretend to be a _woman_ (B) and by 
the frequency of _mistakes_ of a __deceived__ 'interrogator' (C) we will judge whether 
this particular Machine 'can think'...
